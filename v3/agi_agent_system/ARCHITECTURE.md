## AGI Agent System: High-Level Architecture Overview

This document outlines the architecture of the `v3/agi_agent_system`, a multi-agent system designed to achieve user-defined goals through automated planning, code generation, and iterative refinement.

### Core Components:

1.  **Planner Agent (`agents/planner.py`)**:
    *   **Responsibility**: Takes the overall user goal and breaks it down into a sequence of smaller, actionable sub-tasks.
    *   **Output**: A structured plan consisting of tasks, each with a description, priority, and dependencies on other tasks.

2.  **Developer Agent (`agents/developer.py`)**:
    *   **Responsibility**: Receives a specific task from the plan and generates the necessary code to accomplish it. It also provides an explanation of the code and suggests test cases.
    *   **Context**: Considers the current task description and the results of previously completed tasks.
    *   **Output**: A code solution containing the generated code, an explanation, and a list of test cases.

3.  **Critic Agent (`agents/critic.py`)**:
    *   **Responsibility**: Evaluates the code solution generated by the Developer Agent against the task requirements.
    *   **Input**: The task description, the generated code, its explanation, test cases, and results from previous tasks.
    *   **Output**: An evaluation including a quality score (0-1), textual feedback, a list of potential improvements, and a boolean `is_success` flag indicating if the code meets a predefined success threshold.

4.  **Workflow (`workflow/agent_graph.py`)**:
    *   **Responsibility**: Orchestrates the execution flow between the Planner, Developer, and Critic agents using a state machine. It manages the overall process from goal decomposition to final solution.
    *   **Mechanism**: Implemented as a state graph using **LangGraph**. It defines the sequence of agent invocations and the conditions for transitioning between states (e.g., moving to the next task, re-running development after critique).
    *   **State Management**: Maintains the `WorkflowState`, which includes the user's goal, the list of tasks, the current task being processed, iteration counts for development-critique cycles, results of development, and evaluations from the critic.

5.  **Core Modules**:
    *   **Configuration (`core/config.py`)**: Manages system-wide settings loaded from environment variables or defaults (e.g., LLM model path, API keys, temperature, success thresholds for the Critic via the global `config` object).
    *   **LLM (`core/llm.py` - inferred from `get_llm()`)**: Provides the interface to the underlying Large Language Model used by all agents for text generation, planning, coding, and evaluation.
    *   **Memory (`core/memory.py` - inferred from `MemoryManager`)**: Responsible for storing and retrieving data throughout the workflow, such as agent conversations, generated plans, code solutions, and evaluations. This allows for context persistence and potentially for resuming or analyzing past sessions.

### Overall Flow of Execution:

1.  **Goal Input**: The process starts when a user provides a high-level goal, either through a Command Line Interface (CLI) or an API (`main.py`).
2.  **Planning**:
    *   The user's `goal` is passed to the `PlannerAgent`.
    *   The Planner Agent interacts with the LLM to break down the goal into a list of `SubTask` objects, forming a `TaskPlan`. This plan is stored in the `WorkflowState`.
3.  **Development Cycle (Iterative)**:
    *   The workflow selects the current task from the plan.
    *   The `DeveloperAgent` receives the task description (and context from previous tasks, if any).
    *   It interacts with the LLM to generate a `CodeSolution` (code, explanation, test cases). This result is added to the `WorkflowState`.
4.  **Critique Cycle (Iterative)**:
    *   The `CriticAgent` receives the `CodeSolution` and the original task description.
    *   It interacts with the LLM to produce a `CodeEvaluation` (score, feedback, improvements, success status). This evaluation is added to the `WorkflowState`.
5.  **Decision and Iteration**:
    *   The `Workflow` (specifically, the `should_continue` function in `agent_graph.py`) checks the `CodeEvaluation`:
        *   **If `is_success` is true OR a maximum number of iterations for the current task is reached**: The system considers the current task complete.
            *   If there are more tasks in the plan, the workflow moves to the next task, returning to step 3 (Development Cycle).
            *   If all tasks are complete, the workflow ends.
        *   **If `is_success` is false AND maximum iterations are not reached**: The feedback from the Critic is implicitly available (as it's part of the shared state/memory, though direct re-injection into the Developer prompt isn't explicitly shown in `DeveloperAgent.run` but is a common pattern in such loops). The workflow transitions back to the `DeveloperAgent` (step 3) for refinement of the code for the *same* task. The `iterations` count for the current task is incremented.
6.  **Completion**: Once all tasks are successfully completed, the workflow concludes, and the final state (containing all results and evaluations) is returned.

### LangGraph for Orchestration:

The system leverages **LangGraph** to define and manage the complex flow of operations.
*   Agents (Planner, Developer, Critic) are defined as nodes in a state graph.
*   Edges define the transitions between these agents.
*   Conditional edges, based on the output of the Critic Agent (e.g., `should_continue` logic), allow for dynamic routing, enabling iterative refinement of code or progression to subsequent tasks.
*   LangGraph manages the `WorkflowState`, ensuring that each agent has access to the necessary data (goal, current task, previous results, evaluations) as it executes.

This architecture allows for a flexible and robust approach to problem-solving, where tasks are systematically planned, executed, and refined through an automated feedback loop.
